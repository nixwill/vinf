version: "3.8"

services:

  spark-master:
    image: bitnami/spark:3.0.1
    restart: unless-stopped
    environment:
      SPARK_MODE: master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out

  spark-worker:
    image: bitnami/spark:3.0.1
    restart: unless-stopped
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 1
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out

  spark-app:
    build: ./
#    command: ./bin/spark-submit --py-files deps.zip src.py && tail -F nothing
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      INPUT_FILE: /opt/data/freebase-rdf-latest.gz
      OUTPUT_DIR: /opt/out/out
#      OUTPUT_COMPRESSION: org.apache.hadoop.io.compress.GzipCodec
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out
