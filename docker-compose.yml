version: "3.8"

services:

  spark-master:
    image: bitnami/spark:3.0.1
    restart: unless-stopped
    environment:
      SPARK_MODE: master
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out
    networks:
      - spark-net

  spark-worker:
    image: bitnami/spark:3.0.1
    restart: unless-stopped
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 1
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out
    networks:
      - spark-net

  spark-app:
    build: ./
#    command: ./bin/spark-submit --py-files deps.zip src.py && tail -F nothing
    depends_on:
      - spark-master
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      INPUT_FILE: /opt/data/freebase-rdf-latest.gz
      OUTPUT_DIR: /opt/out/out
#      OUTPUT_COMPRESSION: org.apache.hadoop.io.compress.GzipCodec
    volumes:
      - ./data:/opt/data
      - ./out:/opt/out
    networks:
      - spark-net

  elastic:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    environment:
      - discovery.type=single-node
    volumes:
      - es-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - es-net

  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: http://elastic:9200
      ELASTICSEARCH_HOSTS: http://elastic:9200
    networks:
      - es-net

volumes:
  es-data:

networks:
  spark-net:
  es-net:
